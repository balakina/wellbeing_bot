import asyncio
import datetime
import json
import re
import os
from typing import Optional, TypedDict, Dict, Any

from dotenv import load_dotenv

from langgraph.graph import StateGraph, END

from langchain_mcp_adapters.client import MultiServerMCPClient
from langchain_gigachat.chat_models import GigaChat

load_dotenv()


# ============ MCP –ö–õ–ò–ï–ù–¢ ============
async def get_mcp_client():
    return MultiServerMCPClient({
        "wellbeing": {
            "transport": "streamable_http",
            "url": os.getenv("WELLBEING_MCP_URL", "http://127.0.0.1:8100/mcp/")
        }
    })


# ============ LLM ============
def build_llm():
    creds = os.getenv("GIGACHAT_CREDENTIALS", "").strip()
    if not creds:
        raise RuntimeError("–ù–µ—Ç GIGACHAT_CREDENTIALS –≤ .env")

    return GigaChat(
        credentials=creds,
        verify_ssl_certs=os.getenv("GIGACHAT_VERIFY_SSL", "false").lower() == "true",
        scope=os.getenv("GIGACHAT_SCOPE", "GIGACHAT_API_PERS"),
    )


SYSTEM_FOR_TAGS_INTERP_REPLY = """
–¢—ã ‚Äî –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ª–∏—á–Ω–æ–≥–æ –¥–Ω–µ–≤–Ω–∏–∫–∞.
–¢–µ–±–µ –¥–∞—é—Ç —Ç–µ–∫—Å—Ç –∑–∞–ø–∏—Å–∏ –∏ –æ—Ü–µ–Ω–∫—É –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è 1‚Äì5.
–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û JSON:
{
  "tags": "—Å–ª–æ–≤–æ1, —Å–ª–æ–≤–æ2",
  "interpretation": "1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è",
  "reply": "2-4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é"
}

–ü—Ä–∞–≤–∏–ª–∞:
- tags: 2-5 —Ä—É—Å—Å–∫–∏—Ö —Å–ª–æ–≤ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é
- interpretation: –º—è–≥–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Å–º—ã—Å–ª–∞ —Å–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º
- reply: –ø–æ–¥–¥–µ—Ä–∂–∫–∞ + 1 –º–∞–ª–µ–Ω—å–∫–∏–π —à–∞–≥
""".strip()


SYSTEM_FOR_SUMMARY = """
–ê–Ω–∞–ª–∏–∑–∏—Ä—É–π JSON –¥–Ω—è: –∑–∞–ø–∏—Å–∏, mood, —Ç–µ–≥–∏.
–°–≤–æ–¥–∫–∞ –≤ 2-4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö:
- –∫–æ–ª-–≤–æ –∑–∞–ø–∏—Å–µ–π
- —Å—Ä–µ–¥–Ω–∏–π mood
- —Ç–µ–º—ã –¥–Ω—è
- 1 –Ω–∞–±–ª—é–¥–µ–Ω–∏–µ/–ª–∞–π—Ñ—Ö–∞–∫
- –¥–∞–π —Å–æ–≤–µ—Ç, —á—Ç–æ –º–æ–∂–Ω–æ –æ–±—Å—É–¥–∏—Ç—å —Å –ø—Å—Ö–∏—Ö–æ–ª–æ–≥–æ–º
–ë–µ–∑ –¥–∏–∞–≥–Ω–æ–∑–æ–≤.
""".strip()


# ============ –£–¢–ò–õ–ò–¢–´ ============
def is_rating(text: str) -> bool:
    return text.strip() in {"1", "2", "3", "4", "5"}


def is_summary_request(text: str) -> bool:
    t = text.lower()
    return any(x in t for x in ["—Å–≤–æ–¥–∫", "–∏—Ç–æ–≥", "—Ä–µ–∑—é–º–µ", "—á—Ç–æ –±—ã–ª–æ"])


def parse_date(text: str) -> Optional[str]:
    m = re.search(r"\d{4}-\d{2}-\d{2}", text)
    if m:
        return m.group(0)
    if "—Å–µ–≥–æ–¥–Ω—è" in text.lower():
        return datetime.date.today().isoformat()
    return None


async def llm_tags_interp_reply(llm, raw_text: str, mood_score: int) -> tuple[str, str, str]:
    user_prompt = f"""–¢–µ–∫—Å—Ç: "{raw_text}"
Mood: {mood_score}
–í–µ—Ä–Ω–∏ JSON."""

    resp = await llm.ainvoke([
        {"role": "system", "content": SYSTEM_FOR_TAGS_INTERP_REPLY},
        {"role": "user", "content": user_prompt}
    ])

    content = resp.content or ""
    match = re.search(r"\{.*\}", content, re.DOTALL)
    if not match:
        return "", "", "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞–∑–æ–±—Ä–∞—Ç—å –æ—Ç–≤–µ—Ç."

    try:
        data = json.loads(match.group(0))
        return (
            data.get("tags", "") or "",
            data.get("interpretation", "") or "",
            data.get("reply", "") or ""
        )
    except Exception:
        return "", "", content.strip()


async def llm_daily_summary(llm, summary_json: dict) -> str:
    prompt = f"–°–≤–æ–¥–∫–∞ –¥–Ω—è:\n{json.dumps(summary_json, ensure_ascii=False, indent=2)}"
    resp = await llm.ainvoke([
        {"role": "system", "content": SYSTEM_FOR_SUMMARY},
        {"role": "user", "content": prompt}
    ])
    return (resp.content or "").strip()


# ============ –°–û–°–¢–û–Ø–ù–ò–ï ============
class DiaryState(TypedDict, total=False):
    user_input: str
    pending_text: Optional[str]
    route: str
    date: Optional[str]
    out_text: str
    out_tags: str


# ============ –ù–û–î–´ (ctx –±–µ—Ä—ë–º –∏–∑ config) ============
def _ctx(config) -> Dict[str, Any]:
    # ctx –∫–ª–∞–¥–µ–º –≤ config["configurable"]["ctx"]
    try:
        return config["configurable"]["ctx"]
    except Exception:
        raise RuntimeError("–ù–µ –ø–µ—Ä–µ–¥–∞–Ω ctx –≤ config: config={'configurable': {'ctx': ...}}")

async def node_route(state: DiaryState, config) -> DiaryState:
    user = (state.get("user_input") or "").strip()
    if not user:
        return {"route": "empty", "out_text": ""}

    if user.lower() in ("–≤—ã—Ö–æ–¥", "exit", "quit"):
        return {"route": "exit", "out_text": "üëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!"}

    date = parse_date(user)
    if is_summary_request(user) or date:
        return {"route": "summary", "date": date}

    pending = state.get("pending_text")
    if pending:
        if is_rating(user):
            return {"route": "save"}
        return {"route": "need_rating", "out_text": "üòä –û—Ü–µ–Ω–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–π 1‚Äì5:"}

    if is_rating(user):
        return {"route": "rating_without_text", "out_text": "–°–Ω–∞—á–∞–ª–∞ –Ω–∞–ø–∏—à–∏ —Ç–µ–∫—Å—Ç –∑–∞–ø–∏—Å–∏, –ø–æ—Ç–æ–º –ø–æ—Å—Ç–∞–≤—å –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ 1‚Äì5 üôÇ"}

    return {"route": "new_text"}


async def node_summary(state: DiaryState, config) -> DiaryState:
    ctx = _ctx(config)
    llm = ctx["llm"]
    summary_tool = ctx.get("summary_tool")

    date = state.get("date") or datetime.date.today().isoformat()
    if not summary_tool:
        return {"out_text": "‚ùå tool get_daily_summary –Ω–µ –Ω–∞–π–¥–µ–Ω –Ω–∞ MCP —Å–µ—Ä–≤–µ—Ä–µ."}

    try:
        summary = await summary_tool.ainvoke({"date": date})
        text = await llm_daily_summary(llm, summary)
        return {"out_text": f"üìä –°–≤–æ–¥–∫–∞ –∑–∞ {date}:\n\n{text}"}
    except Exception as e:
        return {"out_text": f"‚ùå {e}"}


async def node_new_text(state: DiaryState, config) -> DiaryState:
    user = (state.get("user_input") or "").strip()
    return {"pending_text": user, "out_text": "üòä –û—Ü–µ–Ω–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ 1‚Äì5:"}


async def node_save(state: DiaryState, config) -> DiaryState:
    ctx = _ctx(config)
    llm = ctx["llm"]
    log_entry_tool = ctx.get("log_entry_tool")

    pending_text = (state.get("pending_text") or "").strip()
    mood = int((state.get("user_input") or "0").strip())

    if not log_entry_tool:
        return {"out_text": "‚ùå tool log_entry –Ω–µ –Ω–∞–π–¥–µ–Ω –Ω–∞ MCP —Å–µ—Ä–≤–µ—Ä–µ.", "pending_text": None}

    try:
        tags, interp, reply = await llm_tags_interp_reply(llm, pending_text, mood)

        await log_entry_tool.ainvoke({
            "raw_text": pending_text,
            "mood_score": mood,
            "tags": tags,
            "interpretation": interp
        })

        out = f"ü§ñ {reply}".strip()
        if tags:
            out += f"\nüè∑Ô∏è {tags}"

        return {"out_text": out, "out_tags": tags, "pending_text": None}

    except Exception as e:
        return {"out_text": f"‚ùå {e}", "pending_text": None}


async def node_smalltalk(state: DiaryState, config) -> DiaryState:
    ctx = _ctx(config)
    llm = ctx["llm"]

    user = (state.get("user_input") or "").strip()
    try:
        resp = await llm.ainvoke([{"role": "user", "content": user}])
        return {"out_text": f"ü§ñ {resp.content}".strip()}
    except Exception as e:
        return {"out_text": f"‚ùå LLM: {e}"}


def route_to_next(state: DiaryState) -> str:
    return state.get("route", "smalltalk")


def build_graph():
    g = StateGraph(DiaryState)

    g.add_node("route", node_route)
    g.add_node("summary", node_summary)
    g.add_node("new_text", node_new_text)
    g.add_node("save", node_save)
    g.add_node("smalltalk", node_smalltalk)

    g.set_entry_point("route")

    g.add_conditional_edges(
        "route",
        route_to_next,
        {
            "empty": END,
            "exit": END,
            "summary": "summary",
            "new_text": "new_text",
            "save": "save",
            "need_rating": END,
            "rating_without_text": END,
            "smalltalk": "smalltalk",
        }
    )

    g.add_edge("summary", END)
    g.add_edge("new_text", END)
    g.add_edge("save", END)
    g.add_edge("smalltalk", END)

    return g.compile()


async def main():
    print("üîó –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ MCP —Å–µ—Ä–≤–µ—Ä—É...")
    mcp_client = await get_mcp_client()
    llm = build_llm()

    tools = await mcp_client.get_tools()
    log_entry_tool = next((t for t in tools if t.name == "log_entry"), None)
    summary_tool = next((t for t in tools if t.name == "get_daily_summary"), None)

    if not log_entry_tool:
        print("‚ùå log_entry tool –Ω–µ –Ω–∞–π–¥–µ–Ω! –ü—Ä–æ–≤–µ—Ä—å —Å–µ—Ä–≤–µ—Ä –∏ –ø—É—Ç—å /mcp")
        return

    ctx = {"llm": llm, "log_entry_tool": log_entry_tool, "summary_tool": summary_tool}
    graph = build_graph()

    print("‚úÖ Wellbeing-–¥–Ω–µ–≤–Ω–∏–∫ (LangGraph) –≥–æ—Ç–æ–≤!")
    print("üìù –¢–µ–∫—Å—Ç ‚Üí 1-5 | '—Å–≤–æ–¥–∫–∞' | '–≤—ã—Ö–æ–¥'")

    state: DiaryState = {"pending_text": None}

    while True:
        user = input("\n–¢—ã: ").strip()
        state["user_input"] = user

        new_state = await graph.ainvoke(state, config={"configurable": {"ctx": ctx}})
        out = (new_state.get("out_text") or "").strip()
        if out:
            print("\n" + out)

        state.update(new_state)

        if new_state.get("route") == "exit":
            break


if __name__ == "__main__":
    asyncio.run(main())
